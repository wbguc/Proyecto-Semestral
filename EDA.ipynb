{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76d3c0c",
   "metadata": {},
   "source": [
    "# **Analisis Eda del proyecto**\n",
    "\n",
    "### Apis a utilizar.\n",
    "Banco Mundial (https://data.worldbank.org)  \n",
    "Our World in Data (https://ourworldindata.org)  \n",
    "World Meter (https://worldometer.readthedocs.io/en/latest)  \n",
    "Datos Macro (https://datosmacro.expansion.com/demografia/natalidad)  \n",
    "API (https://opengateway.telefonica.com/apis/population-density-data)  \n",
    "https://www.ine.gob.cl/estadisticas/sociales/censos-de-poblacion-y-vivienda/censo-de-poblacion-y-vivienda\n",
    "\n",
    "### Recordamos las preguntas de investigacion:\n",
    "\n",
    "1) ¿Existe relación entre el nivel de urbanización y las tasas de natalidad?  \n",
    "  \n",
    "2) ¿Existen patrones regionales o económicos que expliquen diferencias en natalidad? \n",
    "  \n",
    "3) ¿Puede predecirse la tasa de natalidad de un país en base a sus condiciones socioeconómicas? \n",
    "  \n",
    "4) ¿Qué  países  se  comportan  como  outliers  (tienen  tasas  de  natalidad  inusuales  dadas  sus \n",
    "características)? \n",
    "  \n",
    "5) ¿Cómo  han  cambiado  las  tasas  de  natalidad  en  las  últimas  dos  décadas,  y  qué  variables  se \n",
    "relacionan con esos cambios? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19886328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias a importar\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import time\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer intento de creacion de dataframe total\n",
    "\"\"\"\n",
    "link_banco_mundial_total = \"https://data.worldbank.org/indicator/SP.POP.TOTL\"\n",
    "link_banco_mundial_urbana = \"https://data.worldbank.org/indicator/SP.URB.TOTL\"\n",
    "link_banco_mundial_fertilidad = \"  https://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL?format=json\"\n",
    "datos_macro_natalidad_html = \"https://datosmacro.expansion.com/demografia/natalidad\"\n",
    "\n",
    "indicadores = [\"SP.POP.TOTL\",\"SP.URB.TOTL\",\"SP.POP.TOTL\"]\n",
    "dataframes = []\n",
    "# Hacemos la primera solicitud para saber cuántas páginas hay\n",
    "for i in indicadores:\n",
    "    url_base = f\"http://api.worldbank.org/v2/country/all/indicator/{i}?format=json&per_page=100\"\n",
    "    response = requests.get(url_base)\n",
    "    data = response.json()\n",
    "    total_pages = data[0]['pages']\n",
    "    print(f\"Total de páginas: {total_pages}\")\n",
    "\n",
    "    # Lista para guardar todos los datos\n",
    "    all_data = []\n",
    "\n",
    "    # Iterar por todas las páginas\n",
    "    for page in range(1, total_pages + 1):\n",
    "        response = requests.get(f\"{url_base}&page={page}\")\n",
    "        page_data = response.json()[1]  # los datos están en la segunda posición\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "    # Normalizamos el JSON y añadimos columna del indicador\n",
    "    df = pd.json_normalize(all_data)\n",
    "    df[\"indicator_id\"] = i # <- esto permite identificar de qué indicador viene\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Unificamos todos los DataFrames en uno solo\n",
    "df_total = pd.concat(dataframes, ignore_index=True)\n",
    "df_total\n",
    "\"\"\"\n",
    "\n",
    "# Version anterior del bloque de codigo inferior\n",
    "'''\n",
    "for i in indicadores:\n",
    "    print(f\"\\nDescargando datos de: {i}\")\n",
    "    url_base = f\"http://api.worldbank.org/v2/country/all/indicator/{i}?format=json&per_page=100\"\n",
    "\n",
    "    # Primera solicitud para saber cuántas páginas hay\n",
    "    response = requests.get(url_base)\n",
    "    \n",
    "    # SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except Exception:\n",
    "        print(f\"No se pudo decodificar JSON para {i} (respuesta vacía o error del servidor).\")\n",
    "        continue\n",
    "\n",
    "    if not isinstance(data, list) or len(data) < 2:\n",
    "        print(f\"Sin datos válidos para {i}.\")\n",
    "        continue\n",
    "\n",
    "    total_pages = data[0]['pages']\n",
    "    print(f\"Total de páginas para {i}: {total_pages}\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    # Iterar por todas las páginas\n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = f\"{url_base}&page={page}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error en la página {page} de {i} (HTTP {response.status_code})\")\n",
    "            continue\n",
    "\n",
    "        #SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "        try: \n",
    "            page_json = response.json()\n",
    "            if len(page_json) < 2:\n",
    "                print(f\"Página {page} vacía para {i}\")\n",
    "                continue\n",
    "            page_data = page_json[1]\n",
    "            all_data.extend(page_data)\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"Error al decodificar JSON en página {page} de {i}\")\n",
    "            continue\n",
    "\n",
    "        # Pequeña pausa para evitar sobrecargar el servidor\n",
    "        time.sleep(0.3)\n",
    "\n",
    "    # SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "    if all_data: \n",
    "        df = pd.json_normalize(all_data)\n",
    "        df[\"indicator_id\"] = i\n",
    "        dataframes.append(df)\n",
    "        print(f\"{len(all_data)} registros añadidos de {i}\")\n",
    "    else:\n",
    "        print(f\"No se añadieron datos para {i}\")\n",
    "\n",
    "# Unificamos todos los DataFrames\n",
    "if dataframes:\n",
    "    df_total = pd.concat(dataframes, ignore_index=True)\n",
    "    print(f\"Data unificada con {len(df_total)} registros totales\")\n",
    "else:\n",
    "    df_total = pd.DataFrame()\n",
    "    print(\"No se pudieron descargar datos válidos.\")\n",
    "\n",
    "df_total.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d8ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (3350692347.py, line 88)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mcontinue # No veo necesario detener la logica, en consideracion de que es poco probable que esta excepcion suceda. Y los datos ya estan en memoria.\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "# Nueva funcion para descargar los archivos desde la API de WorldBank\n",
    "# Ahora deberia de guardar los archivos descargados en un CSV una vez termine\n",
    "# No la he probado\n",
    "\n",
    "def descargar_datos_desde_worldbank():\n",
    "    indicadores = [\"SP.POP.TOTL\", \"SP.URB.TOTL\", \"SP.DYN.TFRT.IN\"]\n",
    "    dataframes = []\n",
    "    archivo_csv = \"datos_worldbank.csv\"\n",
    "\n",
    "    # Verificar si los datos fueron descargados con anterioridad\n",
    "    if path.exists(archivo_csv):\n",
    "        print(f\"Archivo {archivo_csv} encontrado. Cargando datos desde el archivo...\")\n",
    "        df_total = pd.read_csv(archivo_csv)\n",
    "        print(f\"Datos cargados exitosamente: {len(df_total)} registros\")\n",
    "        return df_total\n",
    "\n",
    "    # Si no existe el archivo, descargar los datos\n",
    "    print(\"No se encontro archivo.\\n\"\n",
    "        \"Iniciando descarga de datos desde la API...\")\n",
    "    \n",
    "    for i in indicadores:\n",
    "        print(f\"\\nDescargando datos de: {i}\")\n",
    "        url_base = f\"http://api.worldbank.org/v2/country/all/indicator/{i}?format=json&per_page=100\"\n",
    "\n",
    "        # Primera solicitud para saber cuántas páginas hay\n",
    "        response = requests.get(url_base)\n",
    "        \n",
    "        # SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "        try:\n",
    "            data = response.json()\n",
    "        except Exception:\n",
    "            print(f\"No se pudo decodificar JSON para {i} (respuesta vacía o error del servidor).\")\n",
    "            continue\n",
    "\n",
    "        if not isinstance(data, list) or len(data) < 2:\n",
    "            print(f\"Sin datos válidos para {i}.\")\n",
    "            continue\n",
    "\n",
    "        total_pages = data[0]['pages']\n",
    "        print(f\"Total de páginas para {i}: {total_pages}\")\n",
    "\n",
    "        all_data = []\n",
    "\n",
    "        # Iterar por todas las páginas\n",
    "        for page in range(1, total_pages + 1):\n",
    "            url = f\"{url_base}&page={page}\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error en la página {page} de {i} (HTTP {response.status_code})\")\n",
    "                continue\n",
    "\n",
    "            # SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "            try: \n",
    "                page_json = response.json()\n",
    "                if len(page_json) < 2:\n",
    "                    print(f\"Página {page} vacía para {i}\")\n",
    "                    continue\n",
    "                page_data = page_json[1]\n",
    "                all_data.extend(page_data)\n",
    "\n",
    "            except Exception:\n",
    "                print(f\"Error al decodificar JSON en página {page} de {i}\")\n",
    "                continue\n",
    "\n",
    "            # Pequeña pausa para evitar sobrecargar el servidor\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        # SEGUROS PARA QUE NO LANZE ERROR POR ERRORES DE FORMATO EN ALGUNOS DE LOS LINKS INTERMEDIOS\n",
    "        if all_data: \n",
    "            df = pd.json_normalize(all_data)\n",
    "            df[\"indicator_id\"] = i\n",
    "            dataframes.append(df)\n",
    "            print(f\"{len(all_data)} registros añadidos de {i}\")\n",
    "        else:\n",
    "            print(f\"No se añadieron datos para {i}\")\n",
    "\n",
    "    # Unificamos todos los DataFrames\n",
    "    if dataframes:\n",
    "        df_total = pd.concat(dataframes, ignore_index=True)\n",
    "        print(f\"Data unificada con {len(df_total)} registros totales\")\n",
    "        \n",
    "        # Guardar en CSV\n",
    "        try:\n",
    "            df_total.to_csv(archivo_csv, index=False)\n",
    "            print(f\"Datos guardados exitosamente en {archivo_csv}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar en CSV: {e}\")\n",
    "    else:\n",
    "        df_total = pd.DataFrame()\n",
    "        print(\"No se pudieron descargar datos válidos.\")\n",
    "\n",
    "    return df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e56d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = descargar_datos_desde_worldbank()\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a08dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.groupby(\"indicator.value\").agg(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivotear el df_total para tener columnas por indicador\n",
    "df_pivot = df_total.pivot_table(\n",
    "    index=[\"country.value\", \"date\"],\n",
    "    columns=\"indicator_id\",\n",
    "    values=\"value\"\n",
    ").reset_index()\n",
    "\n",
    "# Calcular nivel de urbanización (% de población urbana)\n",
    "df_pivot[\"urban_rate\"] = (df_pivot[\"SP.URB.TOTL\"] / df_pivot[\"SP.POP.TOTL\"]) * 100\n",
    "\n",
    "# Limpiar años y convertir valores numéricos\n",
    "df_pivot[\"date\"] = df_pivot[\"date\"].astype(int)\n",
    "df_pivot = df_pivot.dropna(subset=[\"SP.DYN.TFRT.IN\", \"urban_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff141e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=df_pivot,\n",
    "    x=\"urban_rate\", \n",
    "    y=\"SP.DYN.TFRT.IN\", \n",
    "    hue='date'\n",
    ")\n",
    "plt.title(\"Relación entre urbanización y tasa de natalidad\")\n",
    "plt.xlabel(\"% población urbana\")\n",
    "plt.ylabel(\"Tasa de fertilidad (hijos por mujer)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ca99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posible alternativa de varios graficos dividos en una matriz 3x3.\n",
    "# 1) Desconozco si los datos realmente llegan desde 1965 al 2010\n",
    "# 1.1) En caso de ser necesario los rangos pueden ajustarse modificando la lista de tuplas: \"year_range\"\n",
    "# 2) No ha sido probado ya que no tengo tiempo de descargar los datos, al tiempo de realizar este commit.\n",
    "\n",
    "# Crear rangos de años de 5 en 5\n",
    "year_ranges = [\n",
    "    (1965, 1969),\n",
    "    (1970, 1974),\n",
    "    (1975, 1979),\n",
    "    (1980, 1984),\n",
    "    (1985, 1989),\n",
    "    (1990, 1994),\n",
    "    (1995, 1999),\n",
    "    (2000, 2004),\n",
    "    (2005, 2010)\n",
    "]\n",
    "\n",
    "# Crear figura con subgráficos\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "axes = axes.flatten()  # Aplanar para iterar fácilmente\n",
    "\n",
    "for idx, (start_year, end_year) in enumerate(year_ranges):\n",
    "\n",
    "    # Filtrar datos para el rango de años actual\n",
    "    mask = (df_filtered['date'] >= start_year) & (df_filtered['date'] <= end_year)\n",
    "    df_range = df_filtered.loc[mask]\n",
    "    \n",
    "    # Crear scatter plot en el subgráfico correspondiente\n",
    "    sc = axes[idx].scatter(\n",
    "        x=df_range[\"urban_rate\"],\n",
    "        y=df_range[\"SP.DYN.TFRT.IN\"],\n",
    "        c=df_range[\"date\"],\n",
    "        cmap=\"viridis\",\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    # Añadir una colorbar individual para cada subgráfico\n",
    "    plt.colorbar(sc, ax=axes[idx])\n",
    "    \n",
    "    axes[idx].set_title(f\"Relación {start_year}-{end_year}\")\n",
    "    axes[idx].set_xlabel(\"% población urbana\")\n",
    "    axes[idx].set_ylabel(\"Tasa de fertilidad\")\n",
    "\n",
    "plt.suptitle(\"Evolución de la relación entre urbanización y tasa de natalidad\", fontsize=14, y=0.95)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc71d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df_pivot.drop(columns=[\"country_name\", \"date\"]).dropna()\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlaciones entre variables socioeconómicas y natalidad\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012ab22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Csv DIRECTO our world in data\n",
    "df = pd.read_csv(\"https://ourworldindata.org/grapher/distribution-of-population-poverty-thresholds.csv?v=1&csvType=full&useColumnShortNames=true\", storage_options = {'User-Agent': 'Our World In Data data fetch/1.0'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd029aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
